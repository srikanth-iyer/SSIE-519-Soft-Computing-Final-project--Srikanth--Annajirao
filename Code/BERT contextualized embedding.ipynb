{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/sk-classroom/asc-bert/blob/main/assignments/assignment_01.ipynb)\n",
    "\n",
    "We will learn how to generate word embeddings using BERT. BERT produces contextualized word embeddings, where the embeddings are computed based on the context of the word. Thus, a single word can have different embeddings based on its context. \n",
    "\n",
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you haven't installed the required packages, please install them using pip\n",
    "# %pip install transformers plotly\n",
    "# %pip install --upgrade nbformat\n",
    "# %pip install torch\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import tqdm as notebook_tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the model and tokenizer\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    \"bert-base-uncased\",output_hidden_states=True\n",
    ")\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BERT, we need to prepare text in ways that BERT can understand. \n",
    "Specifically, we prepend it with ```[CLS]``` and append ```[SEP]```. We will then convert the text to a tensor of token ids, which is ready to be fed into the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text):\n",
    "    text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    segments_ids = torch.ones((1, len(indexed_tokens)), dtype=torch.long)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensor = segments_ids.clone()\n",
    "    return tokenized_text, tokens_tensor, segments_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is segment tensor?\n",
    "BERT models are designed to process sentence pairs, differentiated by 0s and 1s to indicate the first and second sentence respectively. In the case of single-sentence inputs, we assign a vector of 1s to each token, indicating they all belong to the first sentence.\n",
    "\n",
    "Let's get the BERT embeddings for the sentence \"Bank is located in the city of London\". \n",
    "\n",
    "First, let's prepare the text for BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Bank is located in the city of London\"\n",
    "tokenized_text, tokens_tensor, segments_tensor = prepare_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's get the BERT embeddings for each token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(tokens_tensor, segments_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output includes `loss`, `logits`, and `hidden_states`. We will use `hidden_states`, which contains the embeddings of the tokens. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many layers?  13\n",
      "Shape?  torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "hidden_states = outputs.hidden_states\n",
    "\n",
    "print(\"how many layers? \", len(hidden_states))\n",
    "print(\"Shape? \", hidden_states[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hidden states are a list of 13 tensors, where each tensor is of shape (batch_size, sequence_length, hidden_size). The first tensor is the input embeddings, and the subsequent tensors are the hidden states of the BERT layers. \n",
    "\n",
    "So, we have 13 choice of hidden states. Deep layers close to the output capture the context of the word from the previous layers.\n",
    "\n",
    "Here we will take the average over the last four hidden states for each token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compute the embedding of the token\n",
    "emb = torch.zeros((len(tokenized_text),768),dtype=torch.float32)\n",
    "n_layers=4\n",
    "for i in range(n_layers):\n",
    "  emb+=hidden_states[-i-1].squeeze(0)\n",
    "  emb/=n_layers\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emb is of shape (sequence_length, hidden_size). Let us summarize the embeddings of the tokens into a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(text):\n",
    "    tokenized_text, tokens_tensor, segments_tensor = prepare_text(text)\n",
    "    outputs = model(tokens_tensor, segments_tensor)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    emb =  torch.zeros((len(tokenized_text),768),dtype=torch.float32)\n",
    "    n_layers=4 #4 for a1, 1 for a2\n",
    "    for i in range(n_layers):\n",
    "      emb+=hidden_states[-i-1].squeeze(0)\n",
    "      emb/=n_layers\n",
    "    return emb, tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "Let's embed the text and get the embedding of the focal word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m sentences \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# sentence\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# TODO: Go through the data and get the embedding of the focal word.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,(word_pos, sentence, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      7\u001b[0m     _emb, _tokenized_text\u001b[38;5;241m=\u001b[39mget_bert_embeddings(sentence)\n\u001b[0;32m      8\u001b[0m     _emb\u001b[38;5;241m=\u001b[39m_emb[word_pos]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "labels = []  # label\n",
    "emb = []  # embedding\n",
    "sentences = []  # sentence\n",
    "\n",
    "# TODO: Go through the data and get the embedding of the focal word.\n",
    "for i,(word_pos, sentence, label) in train_data.iterrows():\n",
    "    _emb, _tokenized_text=get_bert_embeddings(sentence)\n",
    "    _emb=_emb[word_pos]\n",
    "    emb.append(_emb)\n",
    "    sentences.append(sentence)\n",
    "    labels.append(label)\n",
    "emb=torch.stack(emb)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results \n",
    "\n",
    "Let's plot the embeddings of the focal word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(emb, labels, sentences):\n",
    "    xy = PCA(n_components=2).fit_transform(emb)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        x=xy[:, 0],\n",
    "        y=xy[:, 1],\n",
    "        color=labels,\n",
    "        hover_data=[sentences],\n",
    "        title=\"PCA of Word Embeddings\",\n",
    "    )\n",
    "    fig.update_layout(width=700, height=500)\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "        selector=dict(mode=\"markers\"),\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "emb1 = emb.detach().numpy()\n",
    "plot_result(emb1, labels, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial on other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "# def save_assignment(emb, labels, assignment_id, data_dir):\n",
    "#     K = len(set(labels))\n",
    "#     xy = LinearDiscriminantAnalysis(n_components=K - 1).fit_transform(emb, labels)\n",
    "#     xy_df = pd.DataFrame(xy)\n",
    "#     xy_df[\"label\"] = labels\n",
    "#     xy_df.to_csv(f\"{data_dir}/eval_test_{assignment_id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many layers?  13\n",
      "Shape?  torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "#  Define the model and tokenizer\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    \"bert-base-uncased\",output_hidden_states=True\n",
    ")\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def prepare_text(text):\n",
    "    text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    segments_ids = torch.ones((1, len(indexed_tokens)), dtype=torch.long)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensor = segments_ids.clone()\n",
    "    return tokenized_text, tokens_tensor, segments_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"A Midsummer Night's Dream by William Shakespeare Edited by Barbara A.\"]\n"
     ]
    }
   ],
   "source": [
    "with open('../Text data/a-midsummer-nights-dream_TXT_FolgerShakespeare.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "text = re.sub(r'\\n', ' ', text)  # Remove newline characters\n",
    "text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespaces\n",
    "\n",
    "# Split the textcorpus into a list of sentence strings\n",
    "text_sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "\n",
    "print(text_sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(text):\n",
    "    tokenized_text, tokens_tensor, segments_tensor = prepare_text(text)\n",
    "    outputs = model(tokens_tensor, segments_tensor)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    emb =  torch.zeros((len(tokenized_text),768),dtype=torch.float32)\n",
    "    n_layers=4 #4 for a1, 1 for a2\n",
    "    for i in range(n_layers):\n",
    "      emb+=hidden_states[-i-1].squeeze(0)\n",
    "      emb/=n_layers\n",
    "    return emb, tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.6686e-01, -1.2793e-01, -4.8854e-01,  ..., -8.6284e-02,\n",
       "          8.3359e-02,  1.9924e-01],\n",
       "        [-1.3591e-01,  6.0254e-02, -2.1157e-01,  ..., -1.8625e-01,\n",
       "         -2.9574e-02,  3.0529e-01],\n",
       "        [ 1.8012e-01, -1.9307e-01, -4.3354e-02,  ..., -3.5496e-03,\n",
       "          2.1768e-02, -1.9646e-01],\n",
       "        ...,\n",
       "        [-1.1118e-01, -8.1374e-02, -1.2472e-01,  ...,  2.6131e-01,\n",
       "          7.4739e-02,  2.3104e-01],\n",
       "        [-4.7866e-01, -4.2583e-01, -4.1932e-01,  ...,  8.7290e-02,\n",
       "         -1.7970e-01, -7.3816e-02],\n",
       "        [ 3.9807e-03,  1.2268e-04, -9.7863e-03,  ..., -8.0885e-03,\n",
       "         -1.5587e-02,  9.2318e-03]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_emb, _tokenized_text=get_bert_embeddings(text_sentences[0])\n",
    "_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m text_sentences:\n\u001b[0;32m      2\u001b[0m     _emb, _tokenized_text\u001b[38;5;241m=\u001b[39mget_bert_embeddings(sentence)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(_emb)\n\u001b[0;32m      5\u001b[0m emb\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mstack(emb)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "for sentence in text_sentences:\n",
    "    _emb, _tokenized_text=get_bert_embeddings(sentence)\n",
    "    emb.append(_emb)\n",
    "\n",
    "emb=torch.stack(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the embedding of the token\n",
    "emb = torch.zeros((len(tokenized_text),768),dtype=torch.float32)\n",
    "n_layers=4\n",
    "for i in range(n_layers):\n",
    "  emb+=hidden_states[-i-1].squeeze(0)\n",
    "  emb/=n_layers\n",
    "emb.shape\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    tokenized_text, tokens_tensor, segments_tensor = prepare_text(text)\n",
    "    outputs = model(tokens_tensor, segments_tensor)\n",
    "    hidden_states = outputs.hidden_states\n",
    "    emb =  torch.zeros((len(tokenized_text),768),dtype=torch.float32)\n",
    "    n_layers=4 #4 for a1, 1 for a2\n",
    "    for i in range(n_layers):\n",
    "      emb+=hidden_states[-i-1].squeeze(0)\n",
    "      emb/=n_layers\n",
    "    return emb, tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applsoftcomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
