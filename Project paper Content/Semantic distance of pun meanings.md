- # nature of puns

	- ## keywords in linguistics

	- **Homography** is when a set of words are spelled identically, but have different meanings. It is not necessary for homographic words to be pronounced the same way, which is called** homophony**.

		- [Lyons, John](http://glottopedia.org/index.php/Lyons,_John). 1968. *Introduction to Theoretical Linguistics.* Cambridge: Cambridge University Press.

	- A **homophone** is a word that is pronounced the same (to a varying extent) as another word but differs in meaning. The two words may be spelled the same, for example rose (flower) and rose (past tense of "rise"), or spelled differently, as in rain, reign, and rein. The term homophone sometimes applies to units longer or shorter than words, for example a phrase, letter, or groups of letters which are pronounced the same as a counterpart. Any unit with this property is said to be homophonous.
	    
	  Homophones that are spelled the same are deemed both homographs and homonyms, e.g. the word read, as in "He is well read" (he is very learned) vs. the sentence "I read that book" (I have finished reading that book).  
	  Homophones that are spelled differently are also called **heterographs**, e.g. to, too, and two.  
  
	- In linguistics, **homonyms** are words which are either

		- **homographs**—words that have the same spelling (regardless of pronunciation)—or

		- **homophones**—words that have the same pronunciation (regardless of spelling)—or both.

	- **Paronyms** are words that are pronounced or written in a similar way but which have different lexical meanings. Paronyms contrast with homonyms, which are words with different meaning having the same pronunciation or spelling. Examples of English paronyms include:
	    
	  alternately and alternatively  
	  collision and collusion  
	  conjuncture and conjecture  
	  eclipse and ellipse  
	  excise and exercise  
	  prolepsis and proslepsis  
	  continuous and contiguous  
	  affect and effect  
	  upmost and utmost  
	  deprecate and depreciate  
	    
	  The term paronym can also refer to words that are derived from the same root, i.e. cognate words.  
  
	- A **heteronym** (also known as a heterophone) is a word that has a different pronunciation and meaning from another word but the same spelling. These are homographs that are not homophones. Thus, lead (the metal) and lead (a leash) are heteronyms, but mean (average) and mean (intend) are not, since they are pronounced the same. Heteronym pronunciation may vary in vowel realisation, in stress pattern, or in other ways.

- # bookmarks
	- ### Adamczyk, Magdalena. "The formal composition of puns in Shakespeare's Love's Labour's Lost: a corpus-based study." *Studia Anglica Posnaniensia: International Review of English Studies*, vol. 42, annual 2006, pp. 301+. *Gale Academic OneFile*, link.gale.com/apps/doc/A167977579/AONE?u=nysl_oweb&sid=googleScholar&xid=8103ff3a. Accessed 16 Apr. 2024.
		- Leech's (1974) model of a multi-layered semantic structure, where ultimately also a terminological differentiation is made between the conceptual meaning, labelled "sense", and the remaining types of meaning, subsumed all under a collective name "communicative value", bears some resemblances to Cruse's (1995: 33-49) scrupulous delimitation between genuine meanings, termed likewise "senses", and fake ones, referred to as "facets", (6) and claimed to belong more in the domain of reading/interpretation. (7) Returning to puns, it can be reinstated, this time with the use of Cruse's (1995, 2000) nomenclature, that semantic contrast sufficient to generate a pun is attainable only where fully-fledged senses operate. Unlike facets, which can get simultaneously activated in a single qualifying (non-ambiguous) context, senses are characterized by "mutual antagonism" in that context of this type, where they are admitted individually, always disambiguates them. In other words, whereas facets are capable of generating pure vagueness (i.e. lack of specification) only, where semantic distance does not suffice for a pun to emerge, senses engender genuine ambiguity, the sine qua non of the majority of pun types.
		- ![image.png](../assets/image_1713279031884_0.png){:height 285, :width 438}
		- ![image.png](../assets/image_1713279255719_0.png){:height 320, :width 445}
		- ![image.png](../assets/image_1713280614332_0.png){:height 205, :width 450}
	
	- ### Semantic diversity: A measure of semantic ambiguity based on variability in the contextual usage of words

		- “What makes a word ambiguous? The commonly accepted answer is that words are ambiguous if they have more than one sense or meaning. This raises a further question, however, to which the answer is inevitably subjective: How different must two uses of a word be for them to qualify as separate senses” [Hoffman et al., 2013, p. 719]

		- “an alternative measure of semantic ambiguity that discards the assumption that words have a discrete number of distinct senses or meanings” [Hoffman et al., 2013, p. 719]

		- “ach has a rather different semantic “flavor,” since the context alters the way that we interpret the word. This difference in contextual variability between perjury and predicament is not captured by the traditional definition of semantic ambiguity” [Hoffman et al., 2013, p. 719]

		- “Schwanenflugel and Shoben (1983) proposed that that context availabilitythe ease with which a word brings to mind a particular context—influences word recognition” [Hoffman et al., 2013, p. 719]

		- “contextual distinctiveness, which measures the predictability of a word’s immediate context. For each appearance of a particular word in their corpus, they analyzed the distribution of words occurring within a ten-word window.” [Hoffman et al., 2013, p. 720]

		- “The LSA method utilizes a large corpus divided into a number of discrete contexts, where each context is a sample of text from a particular source.” [Hoffman et al., 2013, p. 720]

		- “LSA then tabulates a cooccurrence matrix registering which words appear in which contexts.” [Hoffman et al., 2013, p. 720]

		- “data-reduction technique called singular value decomposition (SVD)” [Hoffman et al., 2013, p. 720]

		- “This important step reveals latent higher-order relationships between words, based on their patterns of co-occurrence.” [Hoffman et al., 2013, p. 720]

		- “To calculate SemD for a particular word, we examined all of the contexts in which the word appeared and calculated their average” [Hoffman et al., 2013, p. 720]

		- “similarity to one another. When the contexts were very similar to one another on average, this suggested that the word was associated with a fairly restricted set of meanings and was relatively unambiguous. When the contexts associated with a given word were quite dissimilar to one another, this suggested that the meaning of the word was more ambiguous.” [Hoffman et al., 2013, p. 721]

		- “Prior to SVD, values in the matrix were logtransformed. The logs associated with each word were then divided by that word’s entropy (H) in the corpus: H ¼X c pc log pc ð; Þ where c indexes the different contexts in which the word appears and pc denotes the word’s frequency in the context divided by its total frequency in the corpus. These standard transformations were performed to reduce the influence of very high-frequency function words whose patterns of occurrence were not relevant in generating the semantic space (Landauer & Dumais, 1997)” [Hoffman et al., 2013, p. 721]

		- “reduce the influence of very high-frequency function words” [Hoffman et al., 2013, p. 721]

		- “SVD was then used to produce a solution with 300 dimensions, which is in the region of optimum dimensionality for LSA models” [Hoffman et al., 2013, p. 721]

		- “The result of this process was two sets of vectors. First, there was a vector for each word in the corpus, describing its location in the semantic space. These are the vectors typically used in applications of LSA; similarity in the vectors of two words is thought to indicate similarity in their meanings. Second, there was a vector for each context that we analyzed, describing its location in the semantic space. We hypothesized that the similarity between the vectors of two contexts would indicate their similarity in semantic content. These context vectors were used in the calculation of SemD,” [Hoffman et al., 2013, p. 721]

		- “Table 1 Steps in calculating semantic diversity (SemD) Step Procedure 1 Divide each document in the British National Corpus into “contexts” of 1,000 words. 2 Perform latent semantic analysis (LSA) procedure on the 1,000-word contexts. This gives LSA vectors for words (as typically used in LSA applications) and vectors for contexts. 3 For word x, find all of the contexts in which x appears at least once (if more than 2,000 contexts, randomly select 2,000 for analysis). 4 Using the LSA vectors for contexts, compute the similarity of all pairwise combinations of contexts containing x by taking the cosine of their vectors. 5 Take the mean of the cosines, then take the natural log of this and reverse the sign to give the semantic diversity value for x.” [Hoffman et al., 2013, p. 721]
		- “ust as a high cosine between the vectors representing two words is thought to indicate that they are related in meaning, a high cosine between the vectors for two contexts would indicate that they were similar in their topics.” [Hoffman et al., 2013, p. 722]

		- “For a given word, we took all contexts in which it appeared and calculated the cosine between each pair of contexts in the set. We then took the mean of these cosines to represent the average similarity between any two contexts containing the word.” [Hoffman et al., 2013, p. 722]

		- “Using this method, we calculated SemD for all 38,544 words in the corpus” [Hoffman et al., 2013, p. 722]

		- “TASA corpus (Zeno, Ivens, Millard, & Duvvuri, 1995)” [Hoffman et al., 2013, p. 722]

		- “It has also long been argued that abstract words have inherently more variable and context-dependent meanings than do concrete or highly imageable words” [Hoffman et al., 2013, p. 722]

		- “Schwanenflugel and colleagues made the argument that concrete words are generally processed more efficiently than abstract words because they have greater context availability—that is, it is easier to link them to specific contexts” [Hoffman et al., 2013, p. 723]

		- “n alternative approach views representations of word meaning, not as discrete nodes that compete for activation, but as graded and distributed patterns of activation that capture conceptual similarity structure (e.g., Harm & Seidenberg, 2004; Rogers, Lambon Ralph, Garrard, Bozeat, McClelland, Hodges & Patterson, 2004; Rogers & McClelland, 2004; Lambon Ralph, Sage, Jones, & Mayberry, 2010). In such models, similar meanings are represented by similar patterns of activation over the same set of processing units, and similarity of meaning can vary in a continuous fashion. Words with highly stable (i.e., unambiguous) meanings are associated with semantic representations that vary minimally across different uses; words with highly ambiguous meanings are associated with patterns that vary greatly; and the various senses of polysemous words are associated with patterns that are related but somewhat distinct.” [Hoffman et al., 2013, p. 728]
		- “modeling the recognition of homonyms, polysemous words, and unambiguous words in a Hopfield network” [Hoffman et al., 2013, p. 728]

		- “Unambiguous words were always associated with the same pattern, whereas homonyms (like “bank”)wereassociatedwithverydistinct patterns on different presentations. Importantly, polysemous words were, on different presentations, associated with a core semantic pattern distorted by some degree of noise, with each distortion corresponding to one of the word’s different senses. The result was that the various senses of a word had distinct but overlapping patterns of activation.” [Hoffman et al., 2013, p. 728]

		- “Interestingly, this is just the pattern observed in the response times of human beings performing such lexico-semantic tasks as word recognition: Homonyms with two unrelated meanings take longer to recognize than do unambiguous words, but polysemous words with many related meanings are recognized faster than unambiguous words” [Hoffman et al., 2013, p. 728]

		- “The association of a single orthographic representation with a variety of overlapping semantic representations led the model to form a single large attractor basin for the word, allowing it to settle more quickly (and, hence, to recognize the item more rapidly) for polysemous words as compared to unambiguous words. In contrast, homonyms with two nonoverlapping semantic representations were associated with two completely separate attractor basins. Settling thus involved a kind of “competition” between the two attractors that took comparatively longer to resolve.” [Hoffman et al., 2013, p. 728]

		- “Words that consistently appear in very similar contexts are associated with similar patterns of activation whenever they occur” [Hoffman et al., 2013, p. 728]

		- ““gestalt” representations of the meanings of entire sentences by combining the representations of individual words” [Hoffman et al., 2013, p. 729]
		- “This consideration of the Rodd et al. (2004) model also illustrates some limitations of the present work. Specifically, we have considered the degree to which the contexts in which a given word appears vary in their meanings, but we have not considered the extent to which the different contexts cluster into quite distinct meanings. For instance, homonyms like bark may occur in two “kinds” of contexts—one set that mainly pertains to dogs, and another that mainly pertains to trees. The full range of contexts in which bark appears may be quite diverse across these two sets, but much less diverse within them. In contrast, a polysemous word like chance may occur in a broad variety of different contexts that do not tend to naturally fall into clusters. Our measure, SemD, will register both kinds of words as highly semantically diverse, but a model like that described by Rodd et al. (2004) will treat these two situations quite differently, forming two nonoverlapping basins of attraction for homonyms like bark and a single, very broad basin for polysemous words like chance.” [Hoffman et al., 2013, p. 729]

		- “Second, future work should focus on measuring not only the variability in meanings of the various contexts associated with a given word, but also on their apparent substructure—that is, the degree to which the different contexts group into distinct clusters in representational space.” [Hoffman et al., 2013, p. 729]

		- “understand better the apparent processing differences that exist between homonyms and polysemous words” [Hoffman et al., 2013, p. 729]

	- ### Homographic Puns Recognition based on Latent Semantic Structures

		- Redfern divides puns into homophonic puns and homographic puns, which uses homonyms and the polysemy of the word respectively” (Diao et al., 2018, p. 565)

		- “Delabastita also classifies puns into four types: homonyny, homophony, honography, and paronyny.” (Diao et al., 2018, p. 566)

- ## Project notes

	- We are concerned with homographs. These are words that are spelled the same but have different lexical meanings.

		- They may or may not be homophones (pronounced in the same way). That is not relevant to us in this project.  We are interested in words that will be clumped into the same vector in the semantic embedding via BERT.

	- Which model to sample for detection of puns?

		- As a baseline, we finetune BERTbase (Devlin et al., 2019), RoBERTa-base (Liu et al., 2019) and DeBERTa-base (He et al., 2021) to classify whether the given text is a joke without any explanations in the input.

			- Jiao Sun et al., “ExPUNations: Augmenting Puns with Keywords and Explanations” (arXiv, October 24, 2022), [http://arxiv.org/abs/2210.13513](http://arxiv.org/abs/2210.13513).

	- Based on the paper: Semantic diversity: A measure of semantic ambiguity based on variability in the contextual usage of words
		- **Semantic Diversity (SemD)**: The paper introduces a computational measure called Semantic Diversity (SemD), which quantifies the ambiguity of a word based on the variety of contexts it appears in.

		- **Contextual Usage**: Unlike traditional measures that count dictionary definitions, SemD assesses how the meaning of words changes with different linguistic and situational contexts.

		- [**Latent Semantic Analysis (LSA)**: The authors utilize LSA on a large text corpus to estimate semantic similarities across contexts, thereby calculating the SemD for words]

		- **Implications**: SemD is shown to correlate with other linguistic variables and is a strong predictor of semantic judgment performance, offering an objective way to analyze the nuanced, context-dependent variations in word meaning 
	
		- SemD, or Semantic Density, is a measure used to evaluate the richness of word meanings in a text. It’s not directly mentioned in the provided web page context, but based on the related concepts discussed, we can infer that SemD could be compared to other measures of word meaning in the following ways:

		- [**Contextual Richness**: SemD might assess the depth and variety of meanings a word has in different contexts, similar to how the Dual-Attentive Neural Network (DANN) model considers word senses and pronunciation for pun location](https://edgeservices.bing.com/edgesvc/chat?udsframed=1&form=SHORUN&clientscopes=chat,noheader,udsedgeshop,channelstable,ntpquery,devtoolsapi,udsinwin11,udsdlpconsent,udscstart,cspgrd,&shellsig=9af2507d7013ea8b8bb64c74df763c6ad2b6fad5&setlang=en-US&darkschemeovr=1#sjevt%7CDiscover.Chat.SydneyClickPageCitation%7Cadpclick%7C0%7C20174ee5-5523-41de-a921-7a4e5acb9be7%7C%7B%22sourceAttributions%22%3A%7B%22providerDisplayName%22%3A%22In%20this%20pa...%22%2C%22pageType%22%3A%22html%22%2C%22pageIndex%22%3A1%2C%22relatedPageUrl%22%3A%22https%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-030-88480-2_55%22%2C%22lineIndex%22%3A21%2C%22highlightText%22%3A%22In%20this%20paper%2C%20a%20model%20called%20DANN%20(Dual-Attentive%20Neural%20Network)%20is%20proposed%20for%20pun%20location%2C%20effectively%20integrates%20word%20senses%20and%20pronunciation%20with%20context%20information%20to%20address%20two%20kinds%20of%20pun%20at%20the%20same%20time.%22%2C%22snippets%22%3A%5B%5D%7D%7D)[1](https://edgeservices.bing.com/edgesvc/chat?udsframed=1&form=SHORUN&clientscopes=chat,noheader,udsedgeshop,channelstable,ntpquery,devtoolsapi,udsinwin11,udsdlpconsent,udscstart,cspgrd,&shellsig=9af2507d7013ea8b8bb64c74df763c6ad2b6fad5&setlang=en-US&darkschemeovr=1#sjevt%7CDiscover.Chat.SydneyClickPageCitation%7Cadpclick%7C0%7C20174ee5-5523-41de-a921-7a4e5acb9be7%7C%7B%22sourceAttributions%22%3A%7B%22providerDisplayName%22%3A%22In%20this%20pa...%22%2C%22pageType%22%3A%22html%22%2C%22pageIndex%22%3A1%2C%22relatedPageUrl%22%3A%22https%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-030-88480-2_55%22%2C%22lineIndex%22%3A21%2C%22highlightText%22%3A%22In%20this%20paper%2C%20a%20model%20called%20DANN%20(Dual-Attentive%20Neural%20Network)%20is%20proposed%20for%20pun%20location%2C%20effectively%20integrates%20word%20senses%20and%20pronunciation%20with%20context%20information%20to%20address%20two%20kinds%20of%20pun%20at%20the%20same%20time.%22%2C%22snippets%22%3A%5B%5D%7D%7D).

		- **[[Word Sense Disambiguation]] (WSD)**: SemD could be analogous to WSD techniques in determining the correct meaning of a word within a specific context. The DANN model, as described, integrates WSD to improve pun detection.

		- **Pronunciation Relevance**: Like the DANN model, SemD may take into account the pronunciation aspects of words, which can influence their meaning, especially in the case of puns.
			
		In summary, while SemD is not explicitly detailed in the context, it likely shares similarities with the methods used in the DANN model for analyzing word meanings, such as considering context, pronunciation, and disambiguation techniques. The DANN model itself is a sophisticated approach that combines semantic and phonetic features to address the challenges of pun location and interpretation.  
	

	**Challenges and Considerations**  
	
	One of the main challenges in measuring semantic distance in puns is the inherent ambiguity and polysemy (multiple meanings) of words. Puns often rely on these linguistic features to create humor, making it difficult for computational models to determine which meaning is intended and which is the pun.  
	
	Additionally, the context in which a pun is used plays a crucial role in its interpretation. Computational models must be able to understand not only the words themselves but also the broader context in which they are used. This requires a sophisticated understanding of language and the ability to process and analyze large amounts of text data.  
	
	**Conclusion**  
	
	The measurement of semantic distance in puns is a complex task that requires advanced computational techniques and a deep understanding of linguistics. While current methods provide a starting point, there is still much work to be done in refining these techniques to accurately capture the subtleties of puns. As research in this area continues to evolve, we can expect to see more sophisticated models that can better understand and interpret the rich and playful nature of language.  
  
References:

	- Homographic pun location using multi-dimensional semantic relationships.

	- Duluth at SemEval-2017 Task 7: Puns Upon a Midnight Dreary, Lexical Semantics for the Weak and Weary.

	- Homographic Puns Recognition Based on Latent Semantic Structures.

- ### Pun Datasets

	- Pundit

	- Corpus of Puns

	- The Stanford Pun Survey

	- Pun of the Day

		- Not working, website not working

	- SemEval-2017 Task 7

		- [Task Description < SemEval-2017 Task 7 (qcri.org)](https://alt.qcri.org/semeval2017/task7/)

		-

	- ExPUN dataset.

	- WordNet

	- ConceptNet

	- Puns4All

	- That's what she said

		- https://github.com/tansaku/twss

		- funniestcomputer.neurogrid.com/

- Pun generation

	- AmbiPun (Mittal et al., 2022)

	- Finetuned T5 (T5FT).
